{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2b59eb38",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\rcrdo\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import torch\n",
    "from facenet_pytorch import InceptionResnetV1, MTCNN\n",
    "import numpy as np\n",
    "import os\n",
    "from PIL import Image\n",
    "from torchvision import transforms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f7831d5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Inicializar el dispositivo: GPU si está disponible, si no, usar CPU ---\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "# --- Inicializar el detector de rostros MTCNN ---\n",
    "# Este modelo detecta y recorta automáticamente las caras\n",
    "mtcnn = MTCNN(image_size=160, margin=0, device=device)\n",
    "\n",
    "# --- Cargar el modelo de reconocimiento facial FaceNet (entrenado con VGGFace2) ---\n",
    "model = InceptionResnetV1(pretrained='vggface2').eval().to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "54e25b08",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Lista para guardar las imagenes de las personas con acceso\n",
    "authorized_embeddings = []\n",
    "# Lista para guardar los Nombres de las personas con acceso\n",
    "authorized_names = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37c8e9ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Leer imágenes desde la carpeta \"faces\"\n",
    "path = \"faces\"\n",
    "for file in os.listdir(path):\n",
    "    img_path = os.path.join(path, file)\n",
    "    img = Image.open(img_path)\n",
    "\n",
    "    # Usar MTCNN para extraer y recortar el rostro de la imagen\n",
    "    face = mtcnn(img)\n",
    "\n",
    "    if face is not None:\n",
    "        # Obtener el embedding (vector de 512 elementos) del rostro recortado\n",
    "        embedding = model(face.unsqueeze(0).to(device))\n",
    "        print(embedding.detach().cpu())\n",
    "        authorized_embeddings.append(embedding.detach().cpu())  # Guardar el vector\n",
    "        authorized_names.append(os.path.splitext(file)[0])       # Guardar el nombre del archivo sin extensión\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "dc476947",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Iniciar cámara\n",
    "cap = cv2.VideoCapture(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1e4940d",
   "metadata": {},
   "outputs": [],
   "source": [
    "while True:\n",
    "    ret, frame = cap.read()\n",
    "    if not ret:\n",
    "        break  # Si no hay fotograma, salir del bucle\n",
    "    \n",
    "    # Convertir el fotograma de OpenCV (BGR) a formato PIL (RGB)\n",
    "    img = Image.fromarray(cv2.cvtColor(frame, cv2.COLOR_BGR2RGB))\n",
    "\n",
    "    # Usar MTCNN para detectar y recortar el rostro\n",
    "    face = mtcnn(img)\n",
    "\n",
    "    if face is not None:\n",
    "        # Obtener el embedding del rostro detectado\n",
    "        embedding = model(face.unsqueeze(0).to(device))\n",
    "        embedding = embedding.detach().cpu()\n",
    "\n",
    "        # Calcular la distancia entre el rostro detectado y cada rostro autorizado\n",
    "        distances = [torch.norm(e - embedding).item() for e in authorized_embeddings]\n",
    "        min_dist = min(distances)  # Tomar la menor distancia\n",
    "        index = distances.index(min_dist)\n",
    "\n",
    "        # Decidir si es un rostro autorizado o no, según el umbral\n",
    "        name = \"Desconocido\"\n",
    "        if min_dist < 0.9:  # Umbral recomendado (puedes ajustarlo)\n",
    "            name = authorized_names[index]\n",
    "\n",
    "        # Mostrar el nombre y la distancia en pantalla\n",
    "        cv2.putText(frame, f\"{name} ({min_dist:.2f})\", (10, 40),\n",
    "                    cv2.FONT_HERSHEY_SIMPLEX, 1,\n",
    "                    (0, 255, 0) if name != \"Desconocido\" else (0, 0, 255), 2)\n",
    "\n",
    "    # Mostrar el fotograma con los resultados\n",
    "    cv2.imshow(\"Reconocimiento Facial (PyTorch)\", frame)\n",
    "\n",
    "    # Salir al presionar la tecla 'q'\n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        break\n",
    "\n",
    "# --- Liberar recursos al terminar ---\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
