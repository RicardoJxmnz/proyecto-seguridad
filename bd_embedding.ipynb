{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "7d819194",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import torch\n",
    "from facenet_pytorch import InceptionResnetV1, MTCNN\n",
    "import numpy as np\n",
    "import os\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "import pyodbc\n",
    "import io"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "8c600b53",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Inicializar el dispositivo: GPU si está disponible, si no, usar CPU ---\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "# --- Inicializar el detector de rostros MTCNN ---\n",
    "# Este modelo detecta y recorta automáticamente las caras\n",
    "mtcnn = MTCNN(image_size=160, margin=0, device=device)\n",
    "\n",
    "# --- Cargar el modelo de reconocimiento facial FaceNet (entrenado con VGGFace2) ---\n",
    "model = InceptionResnetV1(pretrained='vggface2').eval().to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "8fce0d0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Lista para guardar las imagenes de las personas con acceso\n",
    "authorized_embeddings = []\n",
    "# Lista para guardar los Nombres de las personas con acceso\n",
    "authorized_names = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "a351d570",
   "metadata": {},
   "outputs": [],
   "source": [
    "conn = pyodbc.connect(\n",
    "    \"DRIVER={ODBC Driver 18 for SQL Server};\"\n",
    "    \"SERVER=RICARDO;\"  # Usa el nombre exacto de tu servidor\n",
    "    \"DATABASE=SucursalesMVC;\"\n",
    "    \"Trusted_Connection=yes;\"\n",
    "    \"Encrypt=yes;\"\n",
    "    \"TrustServerCertificate=yes;\"\n",
    ")\n",
    "\n",
    "cursor = conn.cursor()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "5790867e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Leer imágenes desde la carpeta \"faces\"\n",
    "path = \"faces\"\n",
    "for file in os.listdir(path):\n",
    "    img_path = os.path.join(path, file)\n",
    "    img = Image.open(img_path)\n",
    "\n",
    "    # Usar MTCNN para extraer y recortar el rostro de la imagen\n",
    "    face = mtcnn(img)\n",
    "\n",
    "    if face is not None:\n",
    "        # Obtener el embedding (vector de 512 elementos)\n",
    "        embedding = model(face.unsqueeze(0).to(device))  # Resultado: shape [1, 512]\n",
    "        embedding = embedding.detach().cpu()[0]  # Remueve la dimensión batch (queda [512])\n",
    "\n",
    "        # Agrega a lista de vectores autorizados\n",
    "        authorized_embeddings.append(embedding)\n",
    "\n",
    "        # Obtener nombre (sin extensión)\n",
    "        nombre = os.path.splitext(file)[0]\n",
    "        authorized_names.append(nombre)\n",
    "\n",
    "        # Leer imagen original como bytes\n",
    "        with open(img_path, \"rb\") as f:\n",
    "            image_bytes = f.read()\n",
    "\n",
    "        # Insertar en la base de datos (convertido a bytes)\n",
    "        cursor.execute(\"INSERT INTO Embeddings (nombre, embedding, imagen) VALUES (?, ?, ?)\",(nombre, embedding.numpy().tobytes(), image_bytes))\n",
    "        conn.commit()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "0a127988",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mostrando: Bad Bunny\n",
      "Mostrando: Ricardo\n"
     ]
    }
   ],
   "source": [
    "# Consulta: obtener las primeras 5 imágenes\n",
    "cursor.execute(\"SELECT nombre, imagen FROM Embeddings WHERE imagen IS NOT NULL\")\n",
    "\n",
    "# Mostrar las primeras 5 imágenes\n",
    "contador = 0\n",
    "for nombre, image_bytes in cursor.fetchall():\n",
    "    if image_bytes:\n",
    "        image = Image.open(io.BytesIO(image_bytes))\n",
    "        image.show(title=nombre)  # Muestra imagen en visor predeterminado\n",
    "        print(f\"Mostrando: {nombre}\")\n",
    "        \n",
    "        contador += 1\n",
    "        if contador >= 5:\n",
    "            break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "49aea843",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Iniciar cámara\n",
    "cap = cv2.VideoCapture(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "1a31a4d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# === LECTURA DE EMBEDDINGS DESDE LA BASE DE DATOS ===\n",
    "cursor.execute(\"SELECT nombre, embedding FROM Embeddings\")\n",
    "rows = cursor.fetchall()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "8bdd5b2b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2 embeddings cargados desde la base de datos.\n"
     ]
    }
   ],
   "source": [
    "for nombre, embedding_bytes in rows:\n",
    "    vector = np.frombuffer(embedding_bytes, dtype=np.float32)\n",
    "    tensor = torch.tensor(vector)\n",
    "    authorized_embeddings.append(tensor)\n",
    "    authorized_names.append(nombre)\n",
    "\n",
    "print(f\"{len(authorized_embeddings)} embeddings cargados desde la base de datos.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "e0a7c631",
   "metadata": {},
   "outputs": [],
   "source": [
    "while True:\n",
    "    ret, frame = cap.read()\n",
    "    if not ret:\n",
    "        break  # Salir si no hay frame\n",
    "\n",
    "    # Convertir frame a formato PIL (RGB)\n",
    "    img = Image.fromarray(cv2.cvtColor(frame, cv2.COLOR_BGR2RGB))\n",
    "\n",
    "    # Detectar rostro\n",
    "    face = mtcnn(img)\n",
    "\n",
    "    if face is not None:\n",
    "        # Obtener embedding\n",
    "        embedding = model(face.unsqueeze(0).to(device))\n",
    "        embedding = embedding.detach().cpu().squeeze(0)\n",
    "\n",
    "        # Comparar con embeddings autorizados\n",
    "        distances = [torch.norm(e - embedding).item() for e in authorized_embeddings]\n",
    "        min_dist = min(distances)\n",
    "        index = distances.index(min_dist)\n",
    "\n",
    "        # Clasificación\n",
    "        name = \"Desconocido\"\n",
    "        if min_dist < 0.9:\n",
    "            name = authorized_names[index]\n",
    "\n",
    "        # Mostrar resultados\n",
    "        cv2.putText(frame, f\"{name} ({min_dist:.2f})\", (10, 40),\n",
    "                    cv2.FONT_HERSHEY_SIMPLEX, 1,\n",
    "                    (0, 255, 0) if name != \"Desconocido\" else (0, 0, 255), 2)\n",
    "\n",
    "    # Mostrar video\n",
    "    cv2.imshow(\"Reconocimiento Facial (PyTorch)\", frame)\n",
    "\n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        break\n",
    "\n",
    "# === LIBERAR RECURSOS ===\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
